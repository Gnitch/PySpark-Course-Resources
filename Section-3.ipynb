{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0948f021-ef7a-4a84-9718-d145e1c73935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76bbe398-7bfd-4b22-b9f5-3b9aaef58261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae52b7b-575e-4d80-a941-abbdbe10700e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Spark Sql fakeFriends.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b44bed2-9fd2-48be-9e29-2607c72352b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parseLine(line):\n",
    "    line = line.split(\",\")\n",
    "    return Row(id=int(line[0]), \n",
    "               name=str(line[1]), \n",
    "               age=int(line[2]), \n",
    "               friends=int(line[3]))\n",
    "\n",
    "lines = spark.sparkContext.textFile(\"fakefriends.csv\")\n",
    "lines = lines.map(parseLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb3c3dc-492e-4dbb-a3f7-b7926d6b5666",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id=21, name='Miles', age=19, friends=268)\n",
      "Row(id=52, name='Beverly', age=19, friends=269)\n",
      "Row(id=54, name='Brunt', age=19, friends=5)\n",
      "Row(id=106, name='Beverly', age=18, friends=499)\n",
      "Row(id=115, name='Dukat', age=18, friends=397)\n",
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 18|    8|\n",
      "| 19|   11|\n",
      "| 20|    5|\n",
      "| 21|    8|\n",
      "| 22|    7|\n",
      "+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleSchema = spark.createDataFrame(lines).cache()\n",
    "peopleSchema.createOrReplaceTempView(\"people\")\n",
    "\n",
    "teens = spark.sql(\"SELECT * FROM people WHERE age BETWEEN 13 AND 19\")\n",
    "for i, teen in enumerate(teens.collect()):    \n",
    "    if i == 5 : break\n",
    "    print(teen)\n",
    "\n",
    "peopleSchema.groupBy(\"age\").count().orderBy(\"age\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b16d3b-6a99-48d6-b37c-069ac8f33282",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spark Sql  Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "703dedf7-97a4-49e4-967d-9b83e8ad3151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserId: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Friends: integer (nullable = true)\n",
      "\n",
      "+------+--------+---+-------+\n",
      "|UserId|    Name|Age|Friends|\n",
      "+------+--------+---+-------+\n",
      "|     1|Jean-Luc| 26|      2|\n",
      "|    13|Jean-Luc| 56|    444|\n",
      "|    18|Jean-Luc| 45|    455|\n",
      "|    34|Jean-Luc| 43|    249|\n",
      "|    63|Jean-Luc| 58|     54|\n",
      "+------+--------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+----------+\n",
      "|    Name|(Age + 10)|\n",
      "+--------+----------+\n",
      "|    Will|        43|\n",
      "|Jean-Luc|        36|\n",
      "|    Hugh|        65|\n",
      "|  Deanna|        50|\n",
      "|   Quark|        78|\n",
      "+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\")\\\n",
    "        .csv(\"fakeFriendsHeader.csv\")\n",
    "    \n",
    "people.printSchema()\n",
    "people.filter(people[\"Name\"].rlike(\"[\\W-\\W]\")).show(5)\n",
    "people.select(people[\"Name\"], people[\"Age\"]+10).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702f3dd-b416-4cf8-9313-71b33b1e79b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Friends By Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b370cb8-dc94-4c6b-917b-bf96b165e4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "|Age|Avg Friends|\n",
      "+---+-----------+\n",
      "| 18|     343.38|\n",
      "| 19|     213.27|\n",
      "| 20|      165.0|\n",
      "| 21|     350.88|\n",
      "| 22|     206.43|\n",
      "+---+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\")\\\n",
    "        .csv(\"fakeFriendsHeader.csv\")\n",
    "    \n",
    "people.groupBy(\"Age\").agg(functions.round(functions.avg(\"Friends\"), 2).alias(\"Avg Friends\"))\\\n",
    ".sort(\"Age\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d02f9-9dbb-49d4-b41a-b4423a66f59f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Word Count Better Sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a861ce-ffdf-4d44-a019-cb3adc81e18a",
   "metadata": {},
   "source": [
    "#### !!! IMP\n",
    "Dataframes work best with structured Data <br>\n",
    "RDD would be better for this <br>\n",
    "RDD can be converted to Dataframes <br>\n",
    "Basically,<br>\n",
    "**Load Data as an RDD then convert it to Dataframes for further proccessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef2c5b59-6ded-4312-bc71-904503cde4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|      Self|\n",
      "|Employment|\n",
      "|  Building|\n",
      "|        an|\n",
      "|  Internet|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bookDf = spark.read.text(\"Book\")\n",
    "wordDf = bookDf.select(functions.explode(functions.split(bookDf.value, r\"\\W+\")).alias(\"word\"))\n",
    "'''\n",
    "Explode function can be used to explode an Array of Array (nested Array) \n",
    "ArrayType(ArrayType(StringType)) columns to rows on PySpark DataFrame\n",
    "'''\n",
    "wordDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e5a89993-0b08-42dc-84f5-bbe711255abb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Word|count|\n",
      "+----+-----+\n",
      "| you| 1878|\n",
      "|  to| 1828|\n",
      "|your| 1420|\n",
      "| the| 1292|\n",
      "|   a| 1191|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordDf = wordDf.filter(wordDf.word != \"\")\n",
    "wordDfLower = wordDf.select(functions.lower(wordDf.word).alias(\"Word\"))\n",
    "wordDfCount = wordDfLower.groupBy(\"Word\").count()\n",
    "wordDfCount.sort(\"count\", ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c714eb-d464-4f51-abb5-fcd17191a61f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Min Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3c1abec4-fcc6-4e43-96e5-7fd8649bfde5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- StationId: string (nullable = true)\n",
      " |-- Date: integer (nullable = true)\n",
      " |-- MeasureType: string (nullable = true)\n",
      " |-- Temperature: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customSchema = StructType([\n",
    "    StructField(\"StationId\", StringType(), nullable=True),\n",
    "    StructField(\"Date\", IntegerType(), nullable=True),\n",
    "    StructField(\"MeasureType\", StringType(), nullable=True),\n",
    "    StructField(\"Temperature\", FloatType(), nullable=True)\n",
    "])\n",
    "\n",
    "tempDf = spark.read.schema(customSchema).csv(\"1800.csv\")\n",
    "tempDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6666801d-bfca-42bd-86d3-bc0714c40149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minTemp = tempDf.filter(tempDf.MeasureType == \"TMIN\")\n",
    "stationTemp = minTemp.select(\"StationId\", \"Temperature\")\n",
    "minStationTemp = stationTemp.groupBy(\"StationId\").min(\"Temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1894d785-975d-4359-a231-d263957be454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minStationTemp = minStationTemp.withColumn(\"temperature\",\\\n",
    "            functions.round(functions.col(\"min(temperature)\") * 0.1 * (9.0 / 5.0) + 32.0, 2))\\\n",
    "            .select(\"stationID\", \"temperature\").sort(\"temperature\")\n",
    "'''\n",
    "function withColumn ---> To create a new column\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cf1f4144-795d-48d5-b063-668a2ffe7ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITE00100554\t5.36F\n",
      "EZE00100082\t7.70F\n"
     ]
    }
   ],
   "source": [
    "results = minStationTemp.collect()\n",
    "for result in results:\n",
    "    print(result[0] + \"\\t{:.2f}F\".format(result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31693974-b92a-4b15-8a56-d9e4c0f640a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Customer Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89778fd4-f679-4e15-828a-6e38c1fec651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cust_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- amount_spent: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customerSchema = StructType([\n",
    "    StructField(\"cust_id\", IntegerType()),\n",
    "    StructField(\"item_id\", IntegerType()),\n",
    "    StructField(\"amount_spent\", FloatType()),\n",
    "])\n",
    "df = spark.read.schema(customerSchema).csv(\"customer-orders.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84d8ee45-23ff-4475-a8f3-9c3f1db40fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|cust_id|amount_spent|\n",
      "+-------+------------+\n",
      "|     68|     6375.45|\n",
      "|     73|      6206.2|\n",
      "|     39|     6193.11|\n",
      "|     54|     6065.39|\n",
      "|     71|     5995.66|\n",
      "+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"cust_id\").agg(functions.round(functions.sum(\"amount_spent\"), 2)\\\n",
    "                          .alias(\"amount_spent\")).sort(\"amount_spent\", ascending=False).show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
