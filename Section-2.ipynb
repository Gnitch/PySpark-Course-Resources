{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b056ede-e951-4edf-865a-1bbf2a37bb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "from collections import OrderedDict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e2a8688-346c-4a05-b52c-3d0467ba8c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87cab9f-91fa-4fe6-97f3-86461df95b1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ratings Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b6799-3336-4ceb-9fb1-d05c900d9484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"u.data\")\n",
    "ratings = lines.map(lambda each: each.split()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bced4-3d91-4db8-a371-aac77668ff0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings_dict = ratings.countByValue()\n",
    "for key, value in sorted(ratings_dict.items()) :\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7045b0-1252-4a7a-8d0b-00b938986c76",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Friends By Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5842a290-b8ef-4ed5-b9bc-0c34b1dba865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 26, Number of Friends: 242.06\n",
      "Age: 40, Number of Friends: 250.82\n",
      "Age: 68, Number of Friends: 269.60\n",
      "Age: 54, Number of Friends: 278.08\n",
      "Age: 38, Number of Friends: 193.53\n",
      "Age: 56, Number of Friends: 306.67\n"
     ]
    }
   ],
   "source": [
    "lines = sc.textFile(\"fakefriends.csv\")\n",
    "def parseLine(row):\n",
    "    row = row.split(\",\")\n",
    "    age = int(row[2])\n",
    "    friends = int(row[3])\n",
    "    return (age, friends)\n",
    "\n",
    "rdd = lines.map(parseLine)\n",
    "totalByAge = rdd.mapValues(lambda x: (x, 1)).reduceByKey(lambda x, y : (x[0]+y[0], x[1]+y[1]))\n",
    "'''\n",
    "reduceByKey() transformation is used to merge the values of each key using an associative\n",
    "reduce function on PySpark RDD. In the above example 'Age' becomes the key and the rows with\n",
    "the same key are merged based on the lambda function.\n",
    "\n",
    "x[0]+y[0] ---> sum of friends, x[1]+y[1] ---> count of friends\n",
    "'''\n",
    "avgByAge = totalByAge.mapValues(lambda x: x[0]/x[1])\n",
    "for i, row in enumerate(avgByAge.collect()):\n",
    "    print(\"Age: {}, Number of Friends: {:.2f}\".format(row[0], row[1]))\n",
    "    if i==5:break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e981e4-0d9d-4498-bbd7-2a81fb787d16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Min Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835ac58f-d734-4bdc-9128-d4a7c7c249d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"1800.csv\")\n",
    "def parseLine(line):\n",
    "    line = line.split(\",\")\n",
    "    stationId = line[0]\n",
    "    entryType = line[2]\n",
    "    temperature = line[3]\n",
    "    return (stationId, entryType, temperature)\n",
    "        \n",
    "rdd = lines.map(parseLine)\n",
    "minTemp = rdd.filter(lambda x: \"TMIN\" in x[1]).map(lambda x :(x[0],x[2]))\n",
    "results = minTemp.reduceByKey(lambda x, y: min(x, y))\n",
    "results.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30208c9b-8192-4cee-a2c0-42d510babab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0321257b-4b90-4370-b58a-5c533625c72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"Book\")\n",
    "wordsRdd = lines.flatMap(lambda x: x.split())\n",
    "words = wordsRdd.countByValue()\n",
    "\n",
    "for i,(word, count) in enumerate(words.items()) :\n",
    "    if word.encode(\"ascii\", \"ignore\"): print(word, count)            \n",
    "    if i == 5  :break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea3f17-fb0f-4a60-99b1-501518cf8c93",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Better Version with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca34def-24b2-4f30-a0ba-396dc9ecf0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalizeWords(line):\n",
    "    return re.compile(r\"\\W+\").split(line.lower())\n",
    "\n",
    "'''\n",
    "map() function produces one output for one input value, whereas flatMap() function produces\n",
    "an arbitrary no of values as output (ie zero or more than zero) for each input value\n",
    "'''\n",
    "wordsRdd = lines.flatMap(normalizeWords)\n",
    "words = wordsRdd.countByValue()\n",
    "\n",
    "for i,(word, count) in enumerate(words.items()) :\n",
    "    print(word, count)            \n",
    "    if i == 5  :break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147d97b1-7ae5-4100-a8da-895d3baecba4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Sort by word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91d4bd-1540-489e-a65d-cb571adf30c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalizeWords(line):\n",
    "    return re.compile(r\"\\W+\").split(line.lower())\n",
    "\n",
    "wordsRdd = lines.flatMap(normalizeWords)\n",
    "wordCounts = wordsRdd.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x+y)\n",
    "'''\n",
    "In the above example for func reduceByKey 'word' becomes the key\n",
    "'''\n",
    "wordCountsSort = wordCounts.sortBy(lambda x: x[1], ascending=False)\n",
    "results = wordCountsSort.collect()\n",
    "for i,(word, count) in enumerate(results) :\n",
    "    print(word, count)            \n",
    "    if i == 5  :break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d542f-361a-4cb2-9ffb-40595526d188",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Total Spent by Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9145837e-95a7-4ed7-b270-d948e993b7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 6375.45\n",
      "73 6206.20\n",
      "39 6193.11\n",
      "54 6065.39\n",
      "71 5995.66\n",
      "2 5994.59\n"
     ]
    }
   ],
   "source": [
    "def parseLine(line):\n",
    "    line = line.split(\",\")\n",
    "    return (int(line[0]), float(line[2]))\n",
    "\n",
    "lines = sc.textFile(\"customer-orders.csv\")    \n",
    "rdd = lines.map(parseLine)\n",
    "totalSpent = rdd.reduceByKey(lambda x, y: x+y)\n",
    "totalSpentSort = totalSpent.sortBy(lambda x: x[1], ascending=False)\n",
    "# To sort by value\n",
    "results = totalSpentSort.collect()\n",
    "\n",
    "for i,(cust, total) in enumerate(results) :\n",
    "    print(\"{} {:.2f}\".format(cust, total))\n",
    "    if i == 5  :break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
